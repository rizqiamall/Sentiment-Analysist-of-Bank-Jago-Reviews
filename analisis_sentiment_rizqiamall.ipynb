{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec9e120",
   "metadata": {},
   "source": [
    "- Nama            : Rizqi Amalia Kartika\n",
    "- Cohort ID       : MC219D5X1732\n",
    "- Group Belajar   : MC-38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab4966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rizqiamaliakartika/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rizqiamaliakartika/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07f99c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reviewId', 'userName', 'userImage', 'content', 'score',\n",
      "       'thumbsUpCount', 'reviewCreatedVersion', 'at', 'replyContent',\n",
      "       'repliedAt', 'appVersion'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6c9d785-bf3d-478a-a215-29a08b74d45d</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>bagus</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-13 21:00:50</td>\n",
       "      <td>Hai, Jagoan! Terima kasih sudah memberikan ula...</td>\n",
       "      <td>2025-04-13 22:37:48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a06c6e14-f57c-4ca5-82a8-3a98cdb44a29</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>kantongnya berguna sekali. sayangnya utk qris ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.62.3</td>\n",
       "      <td>2025-04-13 20:29:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.62.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9c82e781-14dd-45c1-a2ea-a57de3a437ea</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>love banget sama bank digital 1 ini,, untuk me...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.62.3</td>\n",
       "      <td>2025-04-13 19:57:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.62.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a600c0d-7f09-4cd3-b6c3-bd53a235f1b6</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>baik</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.62.2</td>\n",
       "      <td>2025-04-13 19:32:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.62.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29026806-cc65-452e-8de4-dfb0837b0692</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>oke bgtt ui simpel dan ada kantong buat pisahi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.62.3</td>\n",
       "      <td>2025-04-13 19:04:22</td>\n",
       "      <td>Hai, Jagoan! Terima kasih sudah memberikan ula...</td>\n",
       "      <td>2025-04-14 03:18:39</td>\n",
       "      <td>8.62.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  a6c9d785-bf3d-478a-a215-29a08b74d45d  Pengguna Google   \n",
       "1  a06c6e14-f57c-4ca5-82a8-3a98cdb44a29  Pengguna Google   \n",
       "2  9c82e781-14dd-45c1-a2ea-a57de3a437ea  Pengguna Google   \n",
       "3  1a600c0d-7f09-4cd3-b6c3-bd53a235f1b6  Pengguna Google   \n",
       "4  29026806-cc65-452e-8de4-dfb0837b0692  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0                                              bagus      4              0   \n",
       "1  kantongnya berguna sekali. sayangnya utk qris ...      5              0   \n",
       "2  love banget sama bank digital 1 ini,, untuk me...      5              0   \n",
       "3                                               baik      5              0   \n",
       "4  oke bgtt ui simpel dan ada kantong buat pisahi...      4              0   \n",
       "\n",
       "  reviewCreatedVersion                   at  \\\n",
       "0                  NaN  2025-04-13 21:00:50   \n",
       "1               8.62.3  2025-04-13 20:29:45   \n",
       "2               8.62.3  2025-04-13 19:57:39   \n",
       "3               8.62.2  2025-04-13 19:32:54   \n",
       "4               8.62.3  2025-04-13 19:04:22   \n",
       "\n",
       "                                        replyContent            repliedAt  \\\n",
       "0  Hai, Jagoan! Terima kasih sudah memberikan ula...  2025-04-13 22:37:48   \n",
       "1                                                NaN                  NaN   \n",
       "2                                                NaN                  NaN   \n",
       "3                                                NaN                  NaN   \n",
       "4  Hai, Jagoan! Terima kasih sudah memberikan ula...  2025-04-14 03:18:39   \n",
       "\n",
       "  appVersion  \n",
       "0        NaN  \n",
       "1     8.62.3  \n",
       "2     8.62.3  \n",
       "3     8.62.2  \n",
       "4     8.62.3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"jago_reviews.csv\")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c003d72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "positif    6906\n",
      "negatif    2716\n",
      "netral      378\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def label_sentiment(score):\n",
    "    if score >= 4:\n",
    "        return 'positif'\n",
    "    elif score == 3:\n",
    "        return 'netral'\n",
    "    else:\n",
    "        return 'negatif'\n",
    "\n",
    "df['label'] = df['score'].apply(label_sentiment)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ff9f9",
   "metadata": {},
   "source": [
    "## Skema 1 – SVM + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8f855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # hapus simbol/angka\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['cleaned'] = df['content'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba8052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>Gak bisa masuk padahal dah tau pasword masih a...</td>\n",
       "      <td>gak masuk dah tau pasword aja gak masuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>sengaja saya kasih download supaya bisa kasih ...</td>\n",
       "      <td>sengaja kasih download kasih review tau mengat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>Haloo. Terimakasii sudah membuat apk jago syar...</td>\n",
       "      <td>haloo terimakasii apk jago syariah membantu ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>terbaik memang</td>\n",
       "      <td>terbaik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>bagus</td>\n",
       "      <td>bagus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "6321  Gak bisa masuk padahal dah tau pasword masih a...   \n",
       "206   sengaja saya kasih download supaya bisa kasih ...   \n",
       "7586  Haloo. Terimakasii sudah membuat apk jago syar...   \n",
       "693                                      terbaik memang   \n",
       "3635                                              bagus   \n",
       "\n",
       "                                                cleaned  \n",
       "6321            gak masuk dah tau pasword aja gak masuk  \n",
       "206   sengaja kasih download kasih review tau mengat...  \n",
       "7586  haloo terimakasii apk jago syariah membantu ba...  \n",
       "693                                             terbaik  \n",
       "3635                                              bagus  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['content', 'cleaned']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea01ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Membagi data menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52188d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Menggunakan TF-IDF untuk ekstraksi fitur\n",
    "# vectorizer = TfidfVectorizer()\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147487ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformasi data latih dan data uji\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c527279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.874\n",
      "Laporan Klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.81      0.81      0.81       528\n",
      "      netral       0.30      0.04      0.07        80\n",
      "     positif       0.90      0.95      0.92      1392\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.67      0.60      0.60      2000\n",
      "weighted avg       0.85      0.87      0.86      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Latih model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred = svm_model.predict(X_test_vec)\n",
    "\n",
    "# Evaluasi\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855518ce",
   "metadata": {},
   "source": [
    "## Skema 2 – LSTM + Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df55378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding sequences\n",
    "max_length = 100  # bisa disesuaikan\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode label (string ke angka)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "y_test_enc = label_encoder.transform(y_test)\n",
    "\n",
    "# Untuk LSTM, ubah label ke categorical (one-hot)\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train_enc)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a651b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 71ms/step - accuracy: 0.6797 - loss: 0.7822 - val_accuracy: 0.6960 - val_loss: 0.7331\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.6927 - loss: 0.7353 - val_accuracy: 0.6960 - val_loss: 0.7465\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 82ms/step - accuracy: 0.6842 - loss: 0.7464 - val_accuracy: 0.6960 - val_loss: 0.7332\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - accuracy: 0.6782 - loss: 0.7611 - val_accuracy: 0.6960 - val_loss: 0.7328\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - accuracy: 0.6915 - loss: 0.7331 - val_accuracy: 0.6960 - val_loss: 0.7334\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 kelas: positif, netral, negatif\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "history = model.fit(X_train_pad, y_train_cat, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e12fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6935 - loss: 0.7314\n",
      "Accuracy on testing set: 69.60%\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.00      0.00      0.00       528\n",
      "      netral       0.00      0.00      0.00        80\n",
      "     positif       0.70      1.00      0.82      1392\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.23      0.33      0.27      2000\n",
      "weighted avg       0.48      0.70      0.57      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi akhir\n",
    "loss, acc = model.evaluate(X_test_pad, y_test_cat)\n",
    "print(f\"Accuracy on testing set: {acc * 100:.2f}%\")\n",
    "\n",
    "# Prediksi label kategorikal\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['negatif', 'netral', 'positif']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0786523",
   "metadata": {},
   "source": [
    "## Skema 3 – Logistic Regression + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127baae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.8815\n",
      "Laporan Klasifikasi:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.81      0.82      0.82       528\n",
      "      netral       0.00      0.00      0.00        80\n",
      "     positif       0.91      0.95      0.93      1392\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.57      0.59      0.58      2000\n",
      "weighted avg       0.85      0.88      0.86      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rizqiamaliakartika/PYTHON/studysession/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inisialisasi model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Training model\n",
    "logreg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_logreg = logreg.predict(X_test_vec)\n",
    "\n",
    "# Evaluasi\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "856c5376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks: Jelek banget\n",
      "Prediksi Sentimen: negatif\n"
     ]
    }
   ],
   "source": [
    "# Contoh inference menggunakan Logistic Regression\n",
    "\n",
    "def infer_logreg(text):\n",
    "    # Preprocessing\n",
    "    text_cleaned = clean_text(text)\n",
    "    vectorized = vectorizer.transform([text_cleaned])\n",
    "\n",
    "    # Prediksi\n",
    "    pred = logreg.predict(vectorized)\n",
    "    print(f\"Teks: {text}\")\n",
    "    print(f\"Prediksi Sentimen: {pred[0]}\")\n",
    "\n",
    "infer_logreg(\"Jelek banget\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studysession (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
